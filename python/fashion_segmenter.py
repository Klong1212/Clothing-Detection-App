import cv2
import numpy as np
import torch
import matplotlib.pyplot as plt
from transformers import AutoImageProcessor, AutoModelForSemanticSegmentation, pipeline
from PIL import Image
from ultralytics import YOLO

class SimpleFashionSegmenter:
    """
    ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÅ‡∏ö‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Human Parsing ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏¢‡∏Å‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤
    """
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üöÄ Loading Human Parsing Model on {self.device}...")
        
        # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Human Parsing ‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡πÑ‡∏î‡πâ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        model_name = "mattmdjaga/segformer_b2_clothes"
        
        self.processor = AutoImageProcessor.from_pretrained(model_name)
        self.model = AutoModelForSemanticSegmentation.from_pretrained(model_name)
        self.model.to(self.device)
        self.model.eval()
        
        # ‡πÇ‡∏´‡∏•‡∏î YOLOv8 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö accessories ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        print("  - Loading YOLOv8 for accessories detection...")
        self.yolo = YOLO('yolov8m.pt')
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° CLIP ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤
        print("  - Loading CLIP Classifier...")
        self.classifier = pipeline(
            "zero-shot-image-classification",
            model="openai/clip-vit-base-patch32",
            device=0 if self.device == "cuda" else -1
        )
        
        # Label mapping ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Human Parsing
        # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡πÄ‡∏™‡∏£‡∏¥‡∏° ‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏≠‡∏ß‡∏±‡∏¢‡∏ß‡∏∞
        self.label_names = [
            'Background',      # 0
            'Hat',            # 1 - ‡∏´‡∏°‡∏ß‡∏Å
            'Hair',           # 2 - ‡∏ú‡∏° (‡∏≠‡∏≠‡∏Å)
            'Sunglasses',     # 3 - ‡πÅ‡∏ß‡πà‡∏ô‡∏Å‡∏±‡∏ô‡πÅ‡∏î‡∏î
            'Upper-clothes',  # 4 - ‡πÄ‡∏™‡∏∑‡πâ‡∏≠
            'Skirt',          # 5 - ‡∏Å‡∏£‡∏∞‡πÇ‡∏õ‡∏£‡∏á
            'Pants',          # 6 - ‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á
            'Dress',          # 7 - ‡∏ä‡∏∏‡∏î‡πÄ‡∏î‡∏£‡∏™
            'Belt',           # 8 - ‡πÄ‡∏Ç‡πá‡∏°‡∏Ç‡∏±‡∏î
            'Left-shoe',      # 9 - ‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ã‡πâ‡∏≤‡∏¢
            'Right-shoe',     # 10 - ‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏Ç‡∏ß‡∏≤
            'Face',           # 11 - ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡∏≠‡∏≠‡∏Å)
            'Left-leg',       # 12 - ‡∏Ç‡∏≤‡∏ã‡πâ‡∏≤‡∏¢ (‡∏≠‡∏≠‡∏Å)
            'Right-leg',      # 13 - ‡∏Ç‡∏≤‡∏Ç‡∏ß‡∏≤ (‡∏≠‡∏≠‡∏Å)
            'Left-arm',       # 14 - ‡πÅ‡∏Ç‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (‡∏≠‡∏≠‡∏Å)
            'Right-arm',      # 15 - ‡πÅ‡∏Ç‡∏ô‡∏Ç‡∏ß‡∏≤ (‡∏≠‡∏≠‡∏Å)
            'Bag',            # 16 - ‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤
            'Scarf',          # 17 - ‡∏ú‡πâ‡∏≤‡∏û‡∏±‡∏ô‡∏Ñ‡∏≠
        ]
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏ß‡∏±‡∏¢‡∏ß‡∏∞
        self.clothing_labels = {
            1, 3, 4, 5, 6, 7, 8, 9, 10, 16, 17  # Hat, Sunglasses, Upper, Skirt, Pants, Dress, Belt, Shoes, Bag, Scarf
        }
        
        # YOLO class IDs ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÅ‡∏ü‡∏ä‡∏±‡πà‡∏ô (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° Person)
        self.yolo_fashion_classes = {
            24: 'Handbag',
            26: 'Backpack', 
            27: 'Umbrella',
            28: 'Tie',        # ‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó
            31: 'Suitcase',
        }
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤)
        self.color_map = {
            'Hat': (255, 200, 120),         # ‡∏™‡πâ‡∏°‡∏≠‡πà‡∏≠‡∏ô
            'Sunglasses': (100, 100, 100),  # ‡πÄ‡∏ó‡∏≤
            'Upper-clothes': (150, 255, 180),  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏°‡∏¥‡πâ‡∏ô‡∏ó‡πå
            'Skirt': (255, 150, 200),       # ‡∏ä‡∏°‡∏û‡∏π‡πÄ‡∏Ç‡πâ‡∏°
            'Pants': (180, 200, 255),       # ‡∏ü‡πâ‡∏≤‡∏≠‡πà‡∏≠‡∏ô
            'Dress': (255, 200, 255),       # ‡∏°‡πà‡∏ß‡∏á‡∏≠‡πà‡∏≠‡∏ô
            'Belt': (101, 67, 33),          # ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÄ‡∏Ç‡πâ‡∏°
            'Left-shoe': (200, 180, 255),   # ‡∏°‡πà‡∏ß‡∏á‡∏ü‡πâ‡∏≤
            'Right-shoe': (200, 180, 255),  # ‡∏°‡πà‡∏ß‡∏á‡∏ü‡πâ‡∏≤
            'Bag': (255, 180, 120),         # ‡∏™‡πâ‡∏°‡∏Ñ‡∏£‡∏µ‡∏°
            'Scarf': (220, 160, 255),       # ‡∏°‡πà‡∏ß‡∏á‡∏û‡∏≤‡∏™‡πÄ‡∏ó‡∏•
            'Tie': (50, 100, 180),          # ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏°
            'Watch': (192, 192, 192),       # ‡πÄ‡∏á‡∏¥‡∏ô
            'Necklace': (255, 215, 0),      # ‡∏ó‡∏≠‡∏á
            'Earrings': (255, 182, 193),    # ‡∏ä‡∏°‡∏û‡∏π‡∏≠‡πà‡∏≠‡∏ô
            'Bracelet': (255, 215, 0),      # ‡∏ó‡∏≠‡∏á
            'Ring': (192, 192, 192),        # ‡πÄ‡∏á‡∏¥‡∏ô
            'Handbag': (255, 150, 120),
            'Backpack': (150, 200, 150),
            'Umbrella': (200, 200, 100),
            'Suitcase': (200, 150, 100),
        }
        
        print("‚úÖ Model Ready!\n")
    
    def get_clothing_candidates(self, category):
        """
        ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CLIP ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏¢‡∏≠‡∏∞‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
        """
        candidates = {
            'Hat': ["Baseball Cap", "Beanie", "Beret", "Fedora", "Sun Hat", "Winter Hat", "Panama Hat", "Bucket Hat", "Snapback Cap", "Trucker Hat", "Visor", "Top Hat", "Bowler Hat", "Newsboy Cap", "Cowboy Hat", "Straw Hat"],
            'Upper-clothes': ["Blazer", "Suit Jacket", "T-shirt", "Blouse", "Shirt", "Sweater", "Hoodie", "Tank Top", "Vest", "Cardigan", "Polo Shirt", "Henley Shirt", "Crop Top", "Tube Top", "Off-shoulder Top", "Sweatshirt", "Denim Jacket", "Leather Jacket", "Bolero Jacket", "Sports Coat", "Windbreaker", "Puffer Jacket", "Wool Coat", "Trench Coat", "Peacoat", "Long Sleeve Shirt", "Short Sleeve Shirt", "Button-up Shirt", "Oversized Shirt", "Fitted Shirt"],
            'Skirt': ["Mini Skirt", "Midi Skirt", "Maxi Skirt", "Pleated Skirt", "Pencil Skirt", "A-Line Skirt", "Denim Skirt", "Flared Skirt", "Wrap Skirt", "Asymmetrical Skirt", "Tennis Skirt", "Tulle Skirt", "Slit Skirt"],
            'Pants': ["Jeans", "Slacks", "Cargo Pants", "Wide-leg Trousers", "Leggings", "Chinos", "Dress Pants", "Joggers", "Capri Pants", "Shorts", "Bermuda Shorts", "Hot Pants", "Bike Shorts", "Skinny Jeans", "Bootcut Jeans", "Flared Jeans", "Straight Leg Jeans", "Distressed Jeans", "High-waisted Pants", "Low-rise Pants", "Culottes", "Palazzo Pants"],
            'Dress': ["Cocktail Dress", "Maxi Dress", "Mini Dress", "Shirt Dress", "Wrap Dress", "A-Line Dress", "Evening Gown", "Sundress", "Bodycon Dress", "Flowy Dress", "Shift Dress", "Fit and Flare Dress", "Halter Dress", "Strapless Dress", "One-shoulder Dress", "Backless Dress", "Sheath Dress", "Jumper Dress", "Slip Dress", "Tea Dress"],
            'Left-shoe': ["Sneakers", "High Heels", "Boots", "Sandals", "Flats", "Leather Shoes", "Loafers", "Oxfords", "Ankle Boots", "Knee-high Boots", "Combat Boots", "Chelsea Boots", "Pumps", "Wedges", "Platforms", "Ballet Flats", "Moccasins", "Slip-ons", "Slippers", "Tennis Shoes", "Running Shoes", "Hiking Boots", "Dress Shoes", "Casual Shoes"],
            'Right-shoe': ["Sneakers", "High Heels", "Boots", "Sandals", "Flats", "Leather Shoes", "Loafers", "Oxfords", "Ankle Boots", "Knee-high Boots", "Combat Boots", "Chelsea Boots", "Pumps", "Wedges", "Platforms", "Ballet Flats", "Moccasins", "Slip-ons", "Slippers", "Tennis Shoes", "Running Shoes", "Hiking Boots", "Dress Shoes", "Casual Shoes"],
            'Bag': ["Handbag", "Backpack", "Tote Bag", "Clutch", "Crossbody Bag", "Shoulder Bag", "Messenger Bag", "Satchel", "Hobo Bag", "Bucket Bag", "Drawstring Bag", "Clutch Purse", "Evening Bag", "Weekender Bag", "Travel Bag", "Gym Bag", "Duffel Bag", "Shoulder Purse", "Chain Bag", "Structured Handbag"],
            'Scarf': ["Silk Scarf", "Wool Scarf", "Neck Scarf", "Head Scarf", "Infinity Scarf", "Pashmina", "Cashmere Scarf", "Shawl", "Wrap", "Stole", "Bandana", "Neckerchief"],
            'Sunglasses': ["Aviator Sunglasses", "Wayfarer Sunglasses", "Round Sunglasses", "Cat-eye Sunglasses", "Oversized Sunglasses", "Clubmaster Sunglasses", "Shield Sunglasses", "Gradient Sunglasses", "Mirrored Sunglasses", "Polarized Sunglasses", "Sporty Sunglasses"],
            'Tie': ["Necktie", "Bow Tie", "Slim Tie", "Knit Tie", "Silk Tie", "Wide Tie", "Skinny Tie", "Clip-on Tie"],
            'Watch': ["Wristwatch", "Smart Watch", "Analog Watch", "Digital Watch", "Dress Watch", "Sports Watch", "Luxury Watch", "Casual Watch"],
            'Belt': ["Leather Belt", "Fabric Belt", "Chain Belt", "Wide Belt", "Skinny Belt", "Woven Belt", "Braided Belt", "Western Belt"],
            'Sunglasses': ["Aviator", "Wayfarer", "Round Frame", "Cat-eye", "Oversized", "Clubmaster", "Shield", "Gradient Lens"],
            'Necklace': ["Chain Necklace", "Pendant Necklace", "Choker", "Pearl Necklace", "Statement Necklace", "Lariat Necklace", "Y Necklace", "Layered Necklace"],
            'Earrings': ["Stud Earrings", "Hoop Earrings", "Drop Earrings", "Chandelier Earrings", "Pearl Earrings", "Tassel Earrings"],
            'Bracelet': ["Bangle", "Charm Bracelet", "Chain Bracelet", "Cuff Bracelet", "Tennis Bracelet", "Beaded Bracelet"],
            'Ring': ["Wedding Ring", "Cocktail Ring", "Signet Ring", "Band Ring", "Statement Ring", "Promise Ring"],
        }
        return candidates.get(category, None)
    
    def classify_clothing(self, image, mask, category):
        """
        ‡πÉ‡∏ä‡πâ CLIP ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤
        """
        candidates = self.get_clothing_candidates(category)
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ candidates ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å ‡πÉ‡∏´‡πâ return ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏°
        if candidates is None:
            return category
        
        try:
            # ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ (crop region)
            masked_region = image.copy()
            masked_region[~mask] = 255  # ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≤‡∏ß
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô PIL Image
            pil_image = Image.fromarray(masked_region)
            
            # ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏î‡πâ‡∏ß‡∏¢ CLIP
            results = self.classifier(pil_image, candidate_labels=candidates)
            
            # ‡∏ñ‡πâ‡∏≤ confidence ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ 25% ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏ß‡πà‡∏≤
            if results and results[0]['score'] > 0.25:
                return results[0]['label']
            else:
                return category
                
        except Exception as e:
            print(f"    ‚ö† CLIP classification failed: {e}")
            return category
    
    def detect_accessories_with_yolo(self, image_np):
        """
        ‡πÉ‡∏ä‡πâ YOLOv8 ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö accessories ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó ‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤
        """
        print("üîç Detecting accessories with YOLO...")
        results = self.yolo(image_np, verbose=False)
        
        accessories = []
        
        for result in results:
            boxes = result.boxes
            for box in boxes:
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                
                # ‡πÉ‡∏ä‡πâ threshold ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó (class 28) ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏±‡∏ô‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏•‡∏∞‡∏¢‡∏≤‡∏Å‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
                min_conf = 0.15 if cls == 28 else 0.4
                
                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô class ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÅ‡∏ü‡∏ä‡∏±‡πà‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if cls in self.yolo_fashion_classes and conf > min_conf:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏à‡∏≤‡∏Å bounding box
                    mask = np.zeros(image_np.shape[:2], dtype=bool)
                    mask[y1:y2, x1:x2] = True
                    
                    label = self.yolo_fashion_classes[cls]
                    
                    # ‡∏Ç‡πâ‡∏≤‡∏° Person
                    if label == 'Person':
                        continue
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
                    if label == 'Handbag':
                        label = 'Bag'
                    
                    area = (x2 - x1) * (y2 - y1)
                    
                    print(f"  üéØ Found: {label.upper()} (confidence: {conf:.2f})")
                    
                    # ‡πÉ‡∏ä‡πâ CLIP ‡∏•‡∏≠‡∏á‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°
                    detailed_label = self.classify_clothing(image_np, mask, label)
                    
                    accessories.append({
                        'label': detailed_label,
                        'mask': mask,
                        'area': area,
                        'color': self.color_map.get(label, (150, 150, 150)),
                        'bbox': (x1, y1, x2, y2),
                        'confidence': conf
                    })
                    print(f"     ‚úÖ Classified as: {detailed_label.upper()}")
        
        return accessories
    
    def detect_tie_region(self, image_np, detected_items):
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó‡∏î‡πå‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏∑‡πâ‡∏≠
        """
        print("  üîé Analyzing neck region for tie...")
        
        # ‡∏´‡∏≤ Face ‡πÅ‡∏•‡∏∞ Upper-clothes
        face_item = None
        upper_item = None
        
        for item in detected_items:
            label = item['label']
            if 'Face' in label or label == 'Face':
                face_item = item
                print(f"    ‚úì Found face")
            elif any(x in label for x in ['Upper-clothes', 'Blazer', 'Suit Jacket', 'Shirt', 'T-shirt', 'Blouse']):
                upper_item = item
                print(f"    ‚úì Found upper clothing: {label}")
        
        if face_item is None:
            print("    ‚úó No face detected")
            return None
        if upper_item is None:
            print("    ‚úó No upper clothing detected")
            return None
        
        # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        face_ys, face_xs = np.where(face_item['mask'])
        if len(face_ys) == 0:
            print("    ‚úó Face mask is empty")
            return None
        
        face_bottom = face_ys.max()
        face_center_x = int(face_xs.mean())
        print(f"    üìç Face bottom at y={face_bottom}, center x={face_center_x}")
        
        # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏™‡∏∑‡πâ‡∏≠
        upper_ys, upper_xs = np.where(upper_item['mask'])
        if len(upper_ys) == 0:
            print("    ‚úó Upper clothing mask is empty")
            return None
        
        upper_top = upper_ys.min()
        print(f"    üìç Upper clothing top at y={upper_top}")
        
        # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó‡∏î‡πå‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏™‡∏∑‡πâ‡∏≠
        if face_bottom >= upper_top:
            print(f"    ‚úó No space for tie (face_bottom={face_bottom} >= upper_top={upper_top})")
            return None
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á region ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó
        neck_height = upper_top - face_bottom
        print(f"    üìè Neck height: {neck_height} pixels")
        
        if neck_height < 10:  # ‡∏•‡∏î‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏à‡∏≤‡∏Å 20
            print(f"    ‚úó Neck region too small ({neck_height} < 10 pixels)")
            return None
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î bounding box ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö neck region
        tie_width = int(image_np.shape[1] * 0.08)  # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 8% ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û
        tie_x1 = max(0, face_center_x - tie_width // 2)
        tie_x2 = min(image_np.shape[1], face_center_x + tie_width // 2)
        tie_y1 = face_bottom
        tie_y2 = min(image_np.shape[0], face_bottom + int(neck_height * 2.5))
        
        # ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô neck region
        neck_region = image_np[tie_y1:tie_y2, tie_x1:tie_x2]
        
        if neck_region.size == 0:
            return None
        
        # ‡πÉ‡∏ä‡πâ CLIP ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó‡∏î‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        try:
            pil_image = Image.fromarray(neck_region)
            candidates = ["necktie", "bow tie", "striped tie", "solid tie", "no tie", "bare neck"]
            results = self.classifier(pil_image, candidate_labels=candidates)
            
            print(f"    üî¨ CLIP results for neck region: {results[0]['label']} ({results[0]['score']:.2f})")
            
            # ‡∏ñ‡πâ‡∏≤ confidence ‡∏Ç‡∏≠‡∏á tie ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 20% ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó
            if results and results[0]['score'] > 0.20 and 'tie' in results[0]['label'].lower():
                print(f"  üéØ Found TIE in neck region (CLIP confidence: {results[0]['score']:.2f})")
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á mask ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó
                mask = np.zeros(image_np.shape[:2], dtype=bool)
                mask[tie_y1:tie_y2, tie_x1:tie_x2] = True
                
                detailed_label = self.classify_clothing(image_np, mask, 'Tie')
                
                return {
                    'label': detailed_label,
                    'mask': mask,
                    'area': (tie_x2 - tie_x1) * (tie_y2 - tie_y1),
                    'color': self.color_map.get('Tie', (50, 100, 180)),
                    'bbox': (tie_x1, tie_y1, tie_x2, tie_y2),
                    'confidence': results[0]['score']
                }
        except Exception as e:
            print(f"    ‚ö† Tie detection failed: {e}")
        
        return None
    
    def segment(self, image_path):
        """
        ‡πÅ‡∏ö‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û
        
        Args:
            image_path: ‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            
        Returns:
            original_image, segmentation_map, detected_labels
        """
        print(f"üì∏ Processing: {image_path}")
        
        # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ
        image = Image.open(image_path).convert('RGB')
        image_np = np.array(image)
        
        # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
        inputs = self.processor(images=image, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # 3. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
        print("üîç Detecting clothing items...")
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
        
        # 4. ‡πÅ‡∏õ‡∏•‡∏á output ‡πÄ‡∏õ‡πá‡∏ô segmentation map
        # Resize ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏¥‡∏°
        seg_map = torch.nn.functional.interpolate(
            logits,
            size=image_np.shape[:2],
            mode='bilinear',
            align_corners=False
        )
        seg_map = seg_map.argmax(dim=1)[0].cpu().numpy()
        
        # 5. ‡∏´‡∏≤ labels ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
        unique_labels = np.unique(seg_map)
        detected_items = []
        
        for label_id in unique_labels:
            # ‡∏Ç‡πâ‡∏≤‡∏° Background (0) ‡πÅ‡∏•‡∏∞‡∏≠‡∏ß‡∏±‡∏¢‡∏ß‡∏∞
            if label_id == 0:
                continue
            
            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏≠‡∏ß‡∏±‡∏¢‡∏ß‡∏∞ (Face, Left-leg, Right-leg, Left-arm, Right-arm, Hair)
            if label_id not in self.clothing_labels:
                continue
                
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ label_id ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
            if label_id < len(self.label_names):
                label_name = self.label_names[label_id]
                mask = (seg_map == label_id)
                area = np.sum(mask)
                
                # ‡∏Å‡∏£‡∏≠‡∏á‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (Noise)
                if area > 500:  # ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 500 pixels
                    print(f"  üîç Found: {label_name.upper()} ({area} pixels)")
                    
                    # ‡πÉ‡∏ä‡πâ CLIP ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
                    detailed_label = self.classify_clothing(image_np, mask, label_name)
                    
                    detected_items.append({
                        'label': detailed_label,
                        'mask': mask,
                        'area': area,
                        'color': self.color_map.get(label_name, (200, 200, 200))
                    })
                    print(f"     ‚úÖ Classified as: {detailed_label.upper()}")
        
        # 6. ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö accessories ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢ YOLO
        yolo_items = self.detect_accessories_with_yolo(image_np)
        
        # ‡∏£‡∏ß‡∏° YOLO items ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö detected items (‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥)
        for yolo_item in yolo_items:
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
            is_duplicate = False
            for existing_item in detected_items:
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì overlap
                intersection = np.logical_and(yolo_item['mask'], existing_item['mask'])
                overlap = np.sum(intersection) / np.sum(yolo_item['mask']) if np.sum(yolo_item['mask']) > 0 else 0
                
                if overlap > 0.5:  # ‡∏ñ‡πâ‡∏≤‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50%
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                detected_items.append(yolo_item)
        
        # 7. ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏ô‡πá‡∏Å‡πÑ‡∏ó ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ heuristic detection
        has_tie = any('Tie' in item['label'] or 'tie' in item['label'].lower() for item in detected_items)
        if not has_tie:
            print("üîç Trying heuristic tie detection...")
            tie_item = self.detect_tie_region(image_np, detected_items)
            if tie_item:
                detected_items.append(tie_item)
                print(f"     ‚úÖ Classified as: {tie_item['label'].upper()}")
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á (‡∏ö‡∏ô‡∏•‡∏á‡∏•‡πà‡∏≤‡∏á)
        # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Y ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
        for item in detected_items:
            ys, _ = np.where(item['mask'])
            item['avg_y'] = ys.mean() if len(ys) > 0 else 0
        
        detected_items.sort(key=lambda x: x['avg_y'])
        
        return image_np, seg_map, detected_items
    
    def visualize(self, image, detected_items, alpha=0.5):
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ñ‡∏°‡∏™‡∏µ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
        
        Args:
            image: ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (numpy array)
            detected_items: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
            alpha: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™‡∏Ç‡∏≠‡∏á‡∏™‡∏µ (0-1)
            
        Returns:
            result_image
        """
        print("\nüé® Creating visualization...")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á overlay ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ñ‡∏°‡∏™‡∏µ
        overlay = image.copy()
        
        for item in detected_items:
            mask = item['mask']
            color = item['color']
            
            # ‡∏ñ‡∏°‡∏™‡∏µ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà mask
            overlay[mask] = color
            
            # ‡∏ß‡∏≤‡∏î‡∏Ç‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡∏°‡∏ä‡∏±‡∏î
            contours, _ = cv2.findContours(
                mask.astype(np.uint8),
                cv2.RETR_EXTERNAL,
                cv2.CHAIN_APPROX_SIMPLE
            )
            
            # ‡∏™‡∏µ‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡πâ‡∏°‡∏Å‡∏ß‡πà‡∏≤‡∏™‡∏µ‡∏ñ‡∏°‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢
            border_color = tuple([max(0, c - 50) for c in color])
            cv2.drawContours(overlay, contours, -1, border_color, 2, cv2.LINE_AA)
        
        # ‡∏£‡∏ß‡∏°‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏Å‡∏±‡∏ö‡∏™‡∏µ‡∏ó‡∏µ‡πà‡∏ñ‡∏° (Alpha Blending)
        result = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)
        
        return result
    
    def visualize_with_labels(self, image, detected_items, alpha=0.5):
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏õ‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
        """
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡∏°‡∏™‡∏µ‡πÅ‡∏•‡πâ‡∏ß
        result = self.visualize(image, detected_items, alpha)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠
        for item in detected_items:
            mask = item['mask']
            label = item['label']
            color = item['color']
            
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ bbox (‡∏à‡∏≤‡∏Å YOLO) ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ bbox
            if 'bbox' in item:
                x1, y1, x2, y2 = item['bbox']
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2
                
                # ‡∏ß‡∏≤‡∏î bounding box
                cv2.rectangle(result, (x1, y1), (x2, y2), color, 2)
            else:
                # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á mask
                ys, xs = np.where(mask)
                if len(xs) == 0:
                    continue
                center_x = int(xs.mean())
                center_y = int(ys.mean())
            
            # ‡∏™‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÄ‡∏Ç‡πâ‡∏°‡∏Å‡∏ß‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô)
            text_color = tuple([max(0, c - 80) for c in color])
            
            # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            label_text = label.upper()
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            thickness = 2
            
            (tw, th), _ = cv2.getTextSize(label_text, font, font_scale, thickness)
            
            # ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á
            padding = 6
            bg_pt1 = (center_x - tw//2 - padding, center_y - th - padding)
            bg_pt2 = (center_x + tw//2 + padding, center_y + padding)
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á (‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÅ‡∏™‡∏á)
            sub_overlay = result.copy()
            cv2.rectangle(sub_overlay, bg_pt1, bg_pt2, color, -1)
            result = cv2.addWeighted(sub_overlay, 0.7, result, 0.3, 0)
            
            # ‡∏ß‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            text_pos = (center_x - tw//2, center_y)
            cv2.putText(result, label_text, text_pos, font, font_scale, 
                       (255, 255, 255), thickness + 1, cv2.LINE_AA)
            cv2.putText(result, label_text, text_pos, font, font_scale, 
                       (0, 0, 0), thickness - 1, cv2.LINE_AA)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• confidence ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            if 'confidence' in item:
                conf_text = f"{item['confidence']:.0%}"
                conf_pos = (center_x - tw//2, center_y + th + 5)
                cv2.putText(result, conf_text, conf_pos, font, 0.5, 
                           (255, 255, 255), 2, cv2.LINE_AA)
                cv2.putText(result, conf_text, conf_pos, font, 0.5, 
                           (0, 0, 0), 1, cv2.LINE_AA)
        
        return result


def main():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
    IMAGE_PATH = "114296429.jpg"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
    OUTPUT_SIMPLE = "result_simple.jpg"
    OUTPUT_LABELED = "result_labeled.jpg"
    
    try:
        # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Segmenter
        segmenter = SimpleFashionSegmenter()
        
        # 2. ‡πÅ‡∏ö‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤
        original_image, seg_map, detected_items = segmenter.segment(IMAGE_PATH)
        
        if not detected_items:
            print("\n‚ö†Ô∏è  No clothing items detected!")
            return
        
        # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡πÅ‡∏Ñ‡πà‡∏ñ‡∏°‡∏™‡∏µ)
        result_simple = segmenter.visualize(original_image, detected_items, alpha=0.6)
        
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏õ‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠
        result_labeled = segmenter.visualize_with_labels(original_image, detected_items, alpha=0.5)
        
        # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
        cv2.imwrite(OUTPUT_SIMPLE, cv2.cvtColor(result_simple, cv2.COLOR_RGB2BGR))
        cv2.imwrite(OUTPUT_LABELED, cv2.cvtColor(result_labeled, cv2.COLOR_RGB2BGR))
        
        print(f"\nüíæ Saved results:")
        print(f"  üìÅ {OUTPUT_SIMPLE}")
        print(f"  üìÅ {OUTPUT_LABELED}")
        
        # 6. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        axes[0].imshow(original_image)
        axes[0].set_title("Original Image", fontsize=14, fontweight='bold')
        axes[0].axis('off')
        
        axes[1].imshow(result_simple)
        axes[1].set_title("Segmented (Simple)", fontsize=14, fontweight='bold')
        axes[1].axis('off')
        
        axes[2].imshow(result_labeled)
        axes[2].set_title("Segmented (With Labels)", fontsize=14, fontweight='bold')
        axes[2].axis('off')
        
        plt.tight_layout()
        plt.savefig("comparison.jpg", dpi=150, bbox_inches='tight')
        print(f"  üìÅ comparison.jpg")
        plt.show()
        
        print("\n‚ú® Done!")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()